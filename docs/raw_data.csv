module,summary
streamlit/app.py,"This code uses the Streamlit library to create a web application that allows users to view data from a labeled projects CSV file, view performance metrics for a tag or slice, and make predictions on text using a machine learning model."
app/api.py,"This code is a FastAPI application that provides endpoints for a machine learning project.It includes endpoints for health checks, performance metrics, arguments used for the run, and predictions."
app/gunicorn.py,"This is a Gunicorn config file that sets up the server socket, worker processes, server mechanics, logging, process naming, and server hooks."
app/schemas.py,This code defines a class called Text which takes a string as an argument and has a minimum length of 1.It also defines a class called PredictPayload which takes a list of Text objects as an argument and has a validator to ensure that the list is not empty.
app/data.py,"This code provides functions to preprocess data, encode labels, and generate balanced data splits.It imports json, re, collections, typing, numpy, pandas, nltk, and sklearn."
config/config.py,"This code imports logging, sys, and pathlib, and sets up URLs, directories, stores, and logging configurations.It also sets up MLFlow model registry and a list of stopwords."
tagifai/predict.py,"This code provides a function, predict(), that takes in a list of texts and a dictionary of artifacts from a run and returns a list of predictions for the input texts."
tagifai/utils.py,"This code provides two functions to load and save a dictionary from/to a JSON file, and a function to set seeds for reproducibility."
tagifai/train.py,"This code is a function that trains a model on data using the SGDClassifier, TfidfVectorizer, and RandomOverSampler.It also optimizes the model using Optuna and logs the metrics using MLFlow."
tagifai/evaluate.py,This code provides a function to generate performance metrics for a given set of true labels and predicted labels.It also provides a slicing function to generate metrics for slices of data.
tagifai/main.py,"This code provides a command line interface (CLI) for a tag prediction model.It includes commands to extract, load, and transform data, train a model, optimize hyperparameters, and predict tags."
tagifai/data.py,"This code provides functions to preprocess data, encode labels, and generate balanced data splits.It imports json, re, collections, typing, numpy, pandas, nltk, and sklearn."
airflow/webserver_config.py,"This code provides the default configuration for the Airflow webserver.It includes settings for authentication type, user registration, recaptcha, mail server, and theme."
code/test_utils.py,"This code tests two functions from the tagifai.utils module.The first function, save_and_load_dict, tests the ability to save a dictionary to a file and then load it back."
code/test_predict.py,This code is a pytest function that tests the custom_predict function from the tagifai module.It tests the function with three different thresholds and the expected output for each.
code/test_evaluate.py,"This code tests the tagifai evaluate module.It imports numpy, pandas, pytest, and the slicing module from snorkel.It then creates a dataframe with three entries and tests two slice functions, nlp_cnn and short_text, to make sure they return the correct indices."
code/test_data.py,This code tests various functions related to data preprocessing and manipulation.It imports the necessary libraries and creates a fixture for a dataframe.
code/test_main.py,"This code tests the Tagifai main module by running various commands such as elt-data, train-model, optimize, load-artifacts, and predict-tag."
model/test_behavioral.py,"This code provides three tests for the Tagifai machine learning model.The first test checks for INVariance via verb injection, the second test checks for DIRectional expectations, and the third test checks for Minimum Functionality."
dags/workflows.py,"The code provided is a Python script that creates a DAG (Directed Acyclic Graph) for MLOps tasks.It includes tasks to extract data from a BigQuery data warehouse, validate the data, optimize the data, and train a model."
packages,"The code provided is a list of Python libraries, which are used for various tasks such as machine learning, natural language processing, data analysis, and web development."
extensions,"This is a list of file types and related keywords that are commonly used in software development.These include configuration files (YAML, TOML, JSON, CFG, CSS), source code files (IDX, TXT, PY, MAIN), version control files (HEAD, PACKED-REFS, GITIGNORE, DVCIGNORE), and other files (IPYNB, SAMPLE, INDEX, DOCKERFILE, MAKEFILE, MD"
